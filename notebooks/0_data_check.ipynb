{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9b58092b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROOT: c:\\Users\\sam\\Documents\\VSCode_tunnel\\cv_2024_upscale\n",
      "CWD : c:\\Users\\sam\\Documents\\VSCode_tunnel\\cv_2024_upscale\n"
     ]
    }
   ],
   "source": [
    "import os, sys\n",
    "\n",
    "def find_project_root(start_path):\n",
    "    cur = start_path\n",
    "    while cur != \"/\" and cur != \"\\\\\":\n",
    "        if os.path.isdir(os.path.join(cur, \"src\")):\n",
    "            return cur\n",
    "        cur = os.path.abspath(os.path.join(cur, \"..\"))\n",
    "    raise RuntimeError(\"Project root not found.\")\n",
    "\n",
    "ROOT = find_project_root(os.getcwd())\n",
    "sys.path.append(ROOT)\n",
    "os.chdir(ROOT)\n",
    "\n",
    "print(\"ROOT:\", ROOT)\n",
    "print(\"CWD :\", os.getcwd())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8feecf26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 492 image pairs.\n",
      "torch.Size([4, 3, 64, 64]) torch.Size([4, 3, 256, 256])\n"
     ]
    }
   ],
   "source": [
    "from src.data.dataset_pairs import UpscaleDataset\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "dataset = UpscaleDataset(\"data/train_lr\", \"data/train_hr\")\n",
    "loader = DataLoader(dataset, batch_size=4)\n",
    "\n",
    "for lr, hr in loader:\n",
    "    print(lr.shape, hr.shape)\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6e3b1679",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 3, 64, 64])\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "m = nn.Conv2d(3, 3, kernel_size=3, padding=1)\n",
    "\n",
    "lr, hr = dataset[0]\n",
    "lr = lr.unsqueeze(0)   # (1,3,64,64)\n",
    "\n",
    "out = m(lr)\n",
    "print(out.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "23f36e64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8789446353912354\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(m.parameters(), lr=1e-4)\n",
    "\n",
    "lr, hr = dataset[0]\n",
    "lr = lr.unsqueeze(0)\n",
    "hr = hr.unsqueeze(0)\n",
    "\n",
    "out = m(lr)\n",
    "loss = criterion(out, hr[:, :, ::4, ::4])\n",
    "loss.backward()\n",
    "\n",
    "print(loss.item())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "upsr",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
